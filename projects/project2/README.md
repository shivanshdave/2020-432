# Project 2 for 432

# The Four Deliverables

1. The [Project 2 Proposal Google Form](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#the-project-2-proposal-google-form), due 2020-04-01.
2. The [Main Project 2 Document](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#the-main-project-2-document) (which includes R Markdown and HTML files, plus an tidied .Rds file), due 2020-05-04.
3. The [Project 2 Video Presentation](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#the-project-2-video-presentation), due 2020-05-04.
4. The [End-of-Term Google Form](https://github.com/THOMASELOVE/2020-432/tree/master/projects/project2#the-end-of-term-google-form), also due 2020-05-04, which you'll find at https://bit.ly/432-2020-project2-end-form.

You are permitted to work alone or with a partner for deliverables 1, 2 and 3. Everyone will complete the End-of-Term Google Form on their own.

## NEW! 

[12 Things I Want To See In Your Project 2](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#new-advice-is-there-anything-specific-you-want-to-see-in-project-2) was posted here 2020-04-01. Not an April Fool's joke.

[Questions and Answers](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#questions-and-answers) is just what you'd think. Your questions, our answers.

-----------

# The Project 2 Proposal Google Form

The Project 2 Proposal Google Form is available now at http://bit.ly/432-2020-project2-proposal-form.

- You need to complete this form by 2020-04-01 at the time specified on the [Course Calendar](https://github.com/THOMASELOVE/2020-432/blob/master/calendar.md). 
- The things you will need in order to complete the form are:

1. A **decision** about whether you are going to work alone or with a partner on Project 2. 
      - If you are working in a group of two people, exactly one of you will fill out the form. There is a question on the form which allows you to tell us who your partner is, if you have one.
      - If you commit in the [Proposal Google Form](http://bit.ly/432-2020-project2-proposal-form) to working with a partner, we will generally expect you to maintain that approach through the entire Project, barring extraordinary circumstances. If a change is required, email Dr. Love as soon as possible.
2. A **title** for your Project 2.
      - The instructions say "Please provide a real title, not something like "Project 2 for 432" but something that actually describes the work you're doing. Restrict the length of your title to 100 characters or fewer, including spaces in the count."
3. The **data source(s)** for your Project 2.
      - Details on what sort of data you can use, etc. are [available below](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#advice-for-the-proposal).
      - The instructions on the form say "If you are using more than one source of data, specify them all. Include a URL for any source available on the internet. You need to specify the number of observations in your data, and the key variables that relate to the research question(s) you will specify below. So, you should tell me something about where the data come from, and specify its size, and the key variables that are discussed in your research questions. Follow the Project 2 instructions."
      - The Form restricts the length of this response to 4000 characters, but we expect that most of you will need about half of that.
4. The **research question** (and any critical background) for your Project 2.
      - Details on research questions and examples of old effective questions are [available below](https://github.com/THOMASELOVE/2020-432/blob/master/projects/project2/README.md#advice-for-the-proposal).
      - The instructions on the form say "Your research question should focus the study, determine the methodology, and guide all stages of your data acquisition and analyses, as well as your presentation and reporting. Don't be unrealistic and claim you'll boil the ocean. A single clearly phrased question (and a question ends with a question mark) that links clearly to your data set is what you're looking for. The question must be one that lends itself well to the use of a regression model (you are welcome to adapt any regression modeling strategy connected to the 432 course) to develop an answer. Don't just list broad categories of things you want to explore. Make a commitment to a specific question you will try to address with the data. Then, after specifying the question, feel free to provide whatever background you feel is necessary for Dr. Love and the TAs to understand what you are asking and why the data you propose to use are suitable. Do not use jargon in your response and do not assume we know anything about your topic of interest that hasn't been discussed already in 431-432."
      - After stating the question, provide as much background as is necessary for an intelligent person not familiar with the field of interest that encompasses your research question.
      - For example, if your question is about genomics, do not assume the reader has a substantial education in genomics.  If your question is about sports, do not assume the reader is a sports fan. Avoid field-specific jargon.
      - Assume that your reader has as clear an understanding as you do of all of the material we’ve discussed in our 431 and 432 classes.
      - The Form restricts the length of this response to 4000 characters, but we expect that most of you will need about half of that.

The Form also has a place for other comments or questions for Dr. Love about your Project 2.

When we receive your [Proposal Form](http://bit.ly/432-2020-project2-proposal-form), we will either approve or reject your Project 2 idea. Once we approve your idea, you’re all set.

- If we cannot approve your proposal, we’ll tell you why, and you’ll then edit your response and re-submit.
- The main reason why we don’t approve projects is that we don’t understand your description of your data set, or how your research question can be addressed using your data set - so focus on making those descriptions and questions as clear as possible.

## Advice for the Proposal

Below, you'll find subsections providing:

1. Advice on Developing a Research Question
2. Several Sample Research Questions from Last Year's Class
3. Suggested Data Sources
4. Data Set Specifications, Requirements and Restrictions

## Advice on Developing a Research Question

![](https://github.com/THOMASELOVE/2020-432/blob/master/classes/class19/figures/rq.png)

- A question is expressed so as to elicit information, and **ends with a question mark**. 
- The question must be one that lends itself well to the use of a regression model (you are welcome to adapt any regression modeling strategy connected to the 432 course) to develop an answer.
- You can study anything you like, so long as you steer clear of things that Dr. Love thinks are inappropriate for a course project.

Straightforward questions with a clear link to models we’ve studied or studying are the best option.

Jeff Leek, in his book [How to be a Modern Scientist](https://leanpub.com/modernscientist) has some excellent advice on this. In particular, identify a research question that:

- is concrete, (and for which you can find useful data), and that
- solves a real problem, and that
- gives you an opportunity to do something new,
- that you will feel ownership of, and
- that you want to work on.

I’ll add that your research question needs to be reasonable and plausible given the constraints on your time and energy. This is the time to develop something that can work in this setting, not try to boil the ocean. 

### Sample Research Questions from Last Year

To help guide your thinking, here are seven lightly edited successful research questions (*in your submission, you'd have to include more specific information where I've used parentheses and italics*) from last year's projects. You are welcome to use a similar question in your submission, but it cannot be identical to these.

1. How effectively can we predict whether a county is in the upper third vs. lower third of violent crime rates based on that county's drug overdose rate, race-ethnicity mix, household income and educational attainment?
2. Do patients (*with this diagnosis*) receiving (*treatment A, B or C*) exhibit meaningfully different survival rates, after adjusting for (*the presence or absence of several genetic mutations*) and (*several variables related to their clinical history*)?
3. How effectively can we predict the number of days in the past 30 where a person with a diabetes diagnosis was in poor physical health based on that person's age, sex, race-ethnicity, and (several measures related to social determinants of health)?
4. Does the amount of public transit available (buses and trains per square mile) provide useful information when predicting a city's prevalence of adults receiving primary care within the past year, afer adjusting for (specified covariates)? 
5. What can a model tell us about how hospital efficiency of care (a composite measure incorporating information from ER wait times, purchasing, and percent of personnel who receive the flu vaccine) and hygiene and contamination concerns (including rates of staph infection, C diff, and sepsis/blood infections) are associated with rates of post-surgery complications after serious cardiac events?
6. Can neuronal activity (captured as new activation, sustained activity, or inactive) be predicted effectively from other cell characteristics like age, RNA production, chromatin relaxation, spatial position, and sex?
7. How strong is the association between marijuana exposure and depression among females ages 20-45 participating in NHANES 2015-16 after adjusting for age, sleep hours, annual family income, health insurance coverage, and number of kids who are 5-year-old or younger in the household?

## Suggested Data Sources

Three especially appealing sources that I'd really like to see people use for Project 2 are:

1. The [Health and Retirement Study](https://hrs.isr.umich.edu/data-products/access-to-public-data)
2. The [General Social Survey](https://gssdataexplorer.norc.org/)
3. The many many public use data sets available at [ICSPR](https://www.icpsr.umich.edu/icpsrweb/ICPSR/)

Other sources students have used successfully in the past and that I’m happy to see include:

4. [National Center on Health Statistics](https://www.cdc.gov/nchs/data_access/ftp_data.htm) including NHANES
5. [Behavioral Risk Factor Surveillance System](https://www.cdc.gov/brfss/data_documentation/index.htm)
6. [500 Cities](https://chronicdata.cdc.gov/browse?category=500+Cities)
7. [County Health Rankings](https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation)

## Data Set Specifications/Requirements

- Dr. Love strongly prefers that you use data that can be shared with anyone in the world, but this is not mandatory.
- You will need special approval from Dr. Love (email him to ask for it before submitting the Proposal Form) to do a project that does not have between 250 and 10,000 observations. Anything in that range is fine, and if your data include meaningfully more than 10,000 observations, but you plan to sample down to 10,000, that will be OK. You will just need to let Dr. Love know that in the proposal form.
- Your final analytic tibble (on which you will do all of your analyses) must contain at least 250 observations (with complete data) and at most 10,000 observations on between 5 and 15 variables, excluding the row identifiers (like subject IDs.) 
- Each categorical variable in your final analytic tibble should have each of its categories (levels) occur in at least 25 rows of your data. If that's not the case, you'll have to collapse some categories together.
- At least one of the variables (whether it plays the role of outcome or predictor in your analyses) in your final analytic tibble must be quantitative.
- At least one of the variables (whether it plays the role of outcome or predictor in your analyses) in your final analytic tibble must be categorical and include 3 or more categories (levels).

## Some Restrictions (What data are you *not* allowed to use?)

- No projects on coronavirus or COVID-19, please. If it is important to you to do work in that area, please do it in the setting of [Homework 5](https://github.com/THOMASELOVE/2020-432/tree/master/homework/hw05).
- No hierarchical or nested data. Do not submit a plan to work with data that really require the use of multi-level models. Contact `431-help` to ask before submitting the proposal if you're not sure if a particular data set will be a problem in this regard.
- No data stored as part of any R package, without our prior emailed approval (send email to request approval before submitting the proposal form.)
- You are not allowed to use data sourced from a textbook or other educational resource for learning statistics, data science or related methods.
- You are not allowed to use data any faculty member at CWRU has provided to you for educational (non-research) purposes.
- You cannot reuse the data from your 432 Project 1, although you can use related data to answer new questions. You are welcome to reuse data you used in your 431 project to study new questions if it is otherwise suitable and you haven’t used it in Project 1 for 432.
- Dr. Love is pretty tired of data sourced from Kaggle, from the UC Irvine Machine Learning Repository, from the Cleveland Clinic Lerner College Repository and data from data analysis competitions. Avoid those unless you can make a very strong argument for their relevance to a question of real interest to you.

## What kinds of outcomes/models are appropriate for Project 2?

I can think of six good choices:

1. Quantitative outcome leading to linear regression
2. Binary outcome leading to logistic regression 
3. Count outcome leading to a Poisson or Negative Binomial regression (with or without hurdle or zero-inflation augmentations), or a tobit (censored) regression
4. Ordered multi-categorical outcome leading to a proportional odds logistic regression
5. Unordered multi-categorical outcome leading to a multinomial regression
6. Survival (time-to-event) outcome with right-censoring, leading to a Cox proportional hazards regression 

Any of those six would be fine, assuming the other elements of the proposal worked out well.


-----------

# The Main Project 2 Document

The Main Document includes an R Markdown file, an HTML file and an Rds tidy data set.  

### Submission Details

- The deadline is noon on 2020-05-04, and your Main Document materials will be submitted through the `Project 2 Main Document` link via Canvas.
- The Canvas link should appear on 2020-04-01, and you may submit your Main Document at any time before the deadline once that link is live. 
- If you are working with a partner, one of you should submit the materials to Canvas, and the other partner should submit a note to Canvas indicating that their partner will submit the materials on time.

### General Requirements for your R Markdown and HTML Materials

Your R Markdown document must create an HTML result which:

- includes a meaningful title (of 100 characters or less) that describes your research question, 
- uses attractive HTML formatting (the approaches used in any of the [Project 1 templates](https://github.com/THOMASELOVE/2020-432/tree/master/projects/project1/templates) would be good choices in terms of formatting) 
- incorporates an automated table of contents (so that `toc: TRUE` should be in your YAML materials) 
- uses automatically numbered headings for sections and subsections (so that `number_sections: true` should be in your YAML, too.)
- uses code-folding (so that `code_folding: show` should be in your YAML, as well)
- displays the use of the **tidyverse** for data management, almost without exception
- uses `comment = NA` in the setup chunk to avoid R output being preceded by hashtags `##`
- is developed using **R version 3.6.2** or later, please.

## The Eight Sections of Your Main Document

Your HTML document's eight section headings should match the section numbering and labels specified below.

## Section 1 should be labeled Preliminaries

Here, you will load all necessary R packages for the work you are doing.

- Use `message = FALSE` in the code chunk where the packages are listed to eliminate the messages in the HTML showing warnings about when packages were built or how objects were masked
- Load the `here` package first and the `tidyverse` package last, and avoid loading other packages that are loaded already by the tidyverse. Loading tidyverse loads [the "core" packages listed here](https://www.tidyverse.org/packages/).

## Section 2 should be labeled Research Question

Here, you will identify and describe a researchable question that is amenable to study using statistical tools that are associated with the 432 course. All of the advice from the Proposal Form applies here.

- A question is expressed so as to elicit information, and ends with a question mark. 
- The question must be one that lends itself well to the use of a regression model (you are welcome to adapt any regression modeling strategy connected to the 432 course) to develop an answer.

You can study anything you like, so long as you steer clear of things that Dr. Love thinks are inappropriate for a course project.
Before stating the question, provide as much background as is necessary for an intelligent person not familiar with the field of interest that encompasses your research question.

- For example, if your question is about genomics, do not assume the reader has a substantial education in genomics.  If your question is about sports, do not assume the reader is a sports fan. Avoid field-specific jargon.
- Assume that your reader has as clear an understanding as you do of all of the material we’ve discussed in our 431 and 432 classes.
- Make the question the most important part of this Section, and be sure to state it carefully.

## Section 3 should be labeled Data Source (or Sources)

Here, you must completely identify the source(s) of the data, so that Dr. Love understands what data you are using very well.

- Should the data be available online, you must also provide a URL where the reader can access the data in this section.
- Should the data not be available online, you must provide a detailed description of where the data come from, how it was gathered, and any restrictions that apply (for instance, if the data are not available to the public, be sure that we know that.) 
- You must also provide in this section evidence that you have any and all necessary approvals to use your data in a Project for this course.

By the end of this section, be sure that you have made clear to the reader why your chosen data is worthy of exploration in the context of your reserch question.

## Section 4 should be labeled Ingesting and Tidying the Data

Begin this section by loading in the data you will use. You should use an R Project to do the work, and use the `here` package to simplify the data load-in.

Next, we want to see the work required to manage and tidy the data into the form you used for your analyses. 

- Do not show sanity checks or false starts. Instead, stick to presenting only the activities which are needed to turn the initial data into the analytic tibble you will use for your analyses.
- Use subsections to delineate the management tasks you perform, and provide guidance in English in between the code chunks that helps the reader understand what you are doing every step of the way.
- If you have a categorical variable in your final analytic tibble, each category in that variable should happen in at least 25 rows of your data. If that's not the case, you'll have to collapse some categories together.
- At least one of the variables (outcome or predictor) you are studying must be quantitative, and at least one must be categorical with 3 or more categories.

On Dealing with Missingness

- If you have missing data in an outcome or key predictor variable, we want you to drop those values from your data set in this tidying process.
- If you have missing data in any other variable, we want you to discuss here whether a missing at random assumption is reasonable.
- If so, we want you to use multiple imputation in generating your final analyses (although you are encouraged to consider simple imputation or complete case approaches in your intermediate analytic steps.)
- If not, we suggest you reduce the scope of your data set to eliminate either the observations that are not missing at random, or to eliminate the variables containing those missing values.

The next to last subsection of Section 4 should be a listing of your final analytic data set (just type its name) to prove that you have generated a tibble in R. Call this subsection **Listing the Analytic Tibble**

- This tibble should include any columns of identifying information for the subjects that you deem necessary, plus the variables you intend to use in your Data Analysis.
- Your tibble listing must be the result of a single line of code where you call the name of the data set. You cannot manipulate it in any way. As it will be a tibble, this listing should print only the first 10 rows of the data, and will also provide Dr. Love (in the HTML) with a correct count of the number of rows and number of columns in your analytic data set.
- Your final analytic tibble must contain between 250 and 10,000 observations on between 5 and 15 variables, excluding the row identifiers (like subject IDs.)

The final subsection of Section 4 should be a single line of code where you use the `here` package and the `saveRDS` function to save the final analytic tibble to an .Rds file. Call this subsection **Saving the Analytic Tibble**.

- If Dr. Love is permitted to have access to your data, you will then provide that .Rds file to him as part of your submission.
- If Dr. Love is not permitted to have access to your data, you will need to submit an .Rds file containing two randomly selected and de-identified rows from your tibble. Contact `431-help` if you require assistance building this.

## Section 5 should be labeled Codebook

For each variable in your Analytic Tibble, provide the following in an attractive and user-friendly format:

- the variable's name in the Analytic Tibble you printed at the end of Section 4
- the type of variable (quantitative, count, binary, ordered multi-categorical, unordered multi-categorical, or censored time-to-event)
- a description of what the variable means, in English, with appropriate units of measurement specified, or in the case of categorical variables, specify each possible level of the variable
- the number of missing values of that variable in the Analytic Tibble.

## Section 6 should be labeled Data Analysis

This includes your work to Transform, Visualize and Model your data so as to address your research question. 

- You are welcome to use any reasonable strategy connected to **either 431 or 432** or even something else you’ve learned about to visualize and transform the data.
- You can adapt any **regression modeling strategy connected to the 432 course** to model the data. 

Present the material here in an order that makes sense to you as being of maximum value to your reader. 

- Do not present detours or false starts or sanity checks that detract from the main analyses you wish to present.
- Use subsections to delineate separate analytic tasks, and to guide the reader.

End this section with a clear description of the final model you settle on, remembering that this may require multiple imputation.

## Section 7 should be labeled Conclusions

Here, you will describe, in complete English sentences, what you have learned about your research question by doing the work in the previous sections. 

- Be sure to begin your Conclusions section by restating the research question and then providing a clear answer (which is not likely to be a completely definitive answer) to your question, which is the result of the analytic work you've done.
- The remainder of the Conclusions section should discuss the strengths and limitations of your approach, comment on possible next steps and describe what you would now do differently in studying this question (if anything) having gone through this experience. 
- We expect that a good Conclusions section will require between 250 and 500 words.
 
## Section 8 should be labeled Session Information

Here, you will include the R session information, using `sessioninfo::session_info()`.

-----------

# The Project 2 Video Presentation

This is a short **recorded** video presentation where you display and discuss whatever you feel are the most important parts of Sections 6 and 7 of your Main Document. 

### Submission

The deadline for this presentation is also noon on 2020-05-04.

- Your Video Presentation materials will be submitted through the `Project 2 Video Presentation goes here` link via Canvas. 
- The Canvas link should appear on 2020-04-01, and you may submit your Presentation materials at any time before the deadline once that link is live.
- **Working Alone?** Your presentation should be between 3 and 5 minutes in length. Be sure your name and the date is included in your filename, as in `video_jane_smith_2020-05-04.mp4`.
- **Working with a Partner?** One of you will provide two separate presentations (one from each of you) each of 3-4 minutes in length, so that the total length is 6-8 minutes for your group, along with a written note indicating which of your two presentations should be watched first. The other partner need only submit a note to Canvas indicating that their partner will submit the materials on time. Be sure the name of the person giving the presentation in each video is specified in the filename for that video.

At a minimum, your presentation should specify your research question, highlight key findings, demonstrate the model you developed, and answer the research question. 

- Given the short length of the presentation, that’s probably all you’ll be able to do.
- The first thing you will do on any recording is introduce yourself by name.
- Although it's nice to see you, if possible, I don’t need to be able to see your face, so it’s fine (and appropriate) to show results from a slide deck or from your portfolio. Be sure I can see and hear your video clearly.
- If you use **slides** or anything other than your main document HTML file in your presentation, please submit those materials via Canvas as part of your video presentation materials so that I can follow along in case it's hard to see in the video.
- If you are working with a partner, one of you should present the first half of your presentation, and the other should present the second half of your joint presentation, so that when I watch the two videos back-to-back, I get the experience of watching a thorough single presentation related to the same research question done by two people in different places.

-----------

# The End-of-Term Google Form

You will complete [this end-of-term Google Form](https://bit.ly/432-2020-project2-end-form) also due 2020-05-04, where you will be asked...

1. to summarize the key finding of your study briefly in your own well-chosen set of 50 or fewer words, and 
2. about the most important thing you’ve learned in 432, 
3. about the next step you’re most eager to take in developing yourself as a data scientist, and 
4. about the most important piece of advice you wished you’d heard when starting the 431-432 sequence. 

If you’re working as a pair, each of you must submit the end-of-term Google Form separately. 

The end-of-term Google Form is found at https://bit.ly/432-2020-project2-end-form.

-----------

# Grading Project 2

Project 2 will be graded on a scale from 0 to 100. Students meeting the minimum requirements expressed above successfully and on-time, will receive a minimum score of 80. This includes:

- 10 points for successful completion of the Project 2 Proposal Google Form, due 2020-04-01.
- 40 points for on-time complete submission of all necessary files (.Rmd, .HTML, .Rds) associated with the Main Project 2 Document so that Dr. Love can successfully review them.
- 20 points for on-time complete submission of the Video Presentation materials so that Dr. Love can successfully review them.
- 10 points for on-time completion of [the End-of-Term Google Form](https://bit.ly/432-2020-project2-end-form).

To get to the maximum score of 100, Dr. Love will award up to 20 additional points for especially thoughtful and effective work on:

- the main document 
- the video presentation and/or
- the end-of-term Google Form.

-----------

## NEW ADVICE! Is there anything specific you want to see in Project 2? 

Sure. There are about a dozen things. I want to see...

1. a clear statement of your research question, preceded by an appropriate (but not at all lengthy) background section motivating the question.
2. a clear description of the data to be used, with careful attention to cleaning the data to make the follow-up analyses as straightforward as possible.
3. the use of techniques from the 431-432 sequence for every stage of the data science process, from data ingest and tidying through the cycle of transformation, visualization and modeling, and then finally a careful communication of the end result.
4. the use of regression methods (which can include OLS, logistic models, and the more recently discussed methods for count, multi-categorical and (soon) survival outcomes) that are directly applicable to the research questions you posed at the start.
5. the use of appropriate tools for diagnosing the quality of those models, including visualizations and summary statistics.
6. identification and comparison of candidate models to address your research question(s) if there are real choices to be made (if you have a clear model in mind at the start, there's no need to use "best subsets" or something just to artificially create a competitor.)
7. validation of your models in an appropriate way if prediction is relevant to your research question(s), as I expect it will be.
8. clear evidence that you have thought hard, and well, about what pieces of output, specifically, think in terms of creating meaningful annotations for every single scrap of output that you generate and present: if you cannot think of anything to say about a piece of output easily, why are you including it?
9. a clear re-statement of the research question you asked at the start, now with conclusions that answer those questions (at least partially.)
10. a clear statement of the limitations of your approach, and
11. a clear statement about useful next steps that you would like to try on the data, moving forward
12. an extremely well-organized presentation of the portfolio, well-labeled, with good headings used throughout and making good use of the technology to create a table of contents that helps guide us to specific elements of your work quickly.

-----------

# Questions and Answers

> What's the difference between a count outcome and a quantitative outcome? (posted 2020-04-06)

- The possible values. A quantitative outcome is any quantity - it includes ratios, percentages, fractions, decimal places, negative numbers, anything that can be expressed on a continuous scale in addition to counts. Counts are a subset of quantities - they start at 0 and increase by integers, so those are the only possible values. 
- A Poisson distribution, for instance, would be an option to use in modeling a count. A Normal distribution is what we typically use for other types of quantitative outcomes.

> Am I right in thinking that you don't want us to impute an outcome in Project 2? (posted 2020-04-06)

That's correct. I do not. If you have a key predictor that your research question is focused on (for instance, did receipt of this treatment affect the outcome, adjusting for these covariates), I am reluctant to have you impute that "treatment" either. I'm happiest when you're only imputing variables you are adjusting for as covariates in your models.

> I am pondering how to move forward with missingness in my data. The codebook suggests that some subgroups (they specifically highlighted black males) tend to not respond to questions regarding high risk behaviors in similar surveys. I am looking at illicit drug use in my model, and there is missingness in the variables I am using. In the Project 2 instructions, you write: If missingness is not random, we suggest you reduce the scope of your data set to eliminate either the observations that are not missing at random, or to eliminate the variables containing those missing values. Can you provide some insight on how to move forward with the missingness here? 

- "Missing at random" isn't a great name, as we discussed. It doesn't mean "missing arbitrarily" but rather it means that the missingness can be fully accounted for by variables where complete information is available. 
- "Missing not at random" means that the missingness depends on things we DON'T have in our data set.
- If black males are believed to be less likely to respond, then your imputation models should include both race and sex. If each of those variables in is your data, then imputation may be reasonable. If they're not, then you have a real problem, and would need to, for instance, select a different set of variables to study. That's the kind of thing you want to talk to us about at `431-help`. 

> A large percentage of the missing data in my study is missing age information. I would like to impute age (as opposed to dropping the subjects with missing age) but to do so, I need to assume that age is missing at random (or missing completely at random.) Is there something I can analyze in my data that would help me assess this assumption? Perhaps how correlated the observed ages are with other variables in my data? Or should I just think about whether some external factor could be a reason why age would be missing? (posted 2020-04-27)

There is nothing in your data set that can help you answer the question of whether it is reasonable to assume "missing at random" (MAR) or not for the age variable.  The missing at random assumption means that you assume that the variables that are available and complete in your data set for these cases with (for instance) missing ages, are sufficient to allow you to impute age - basically you need to make the case that there's no variable (or group of variables) hidden to you which actually determines whether the age of the subject will be missing or shown. So, how correlated your known ages are with any other variable in your data set is of no help in making this determination, because the question is not whether the model for imputing age within your data does a good/fair/poor/excellent job of predicting age, the question is whether there is something NOT included in your data that would be driving whether age is missing or not. Essentially, if you believe (and can make the case) that the reason for missingness is attributable to variables available to you, then imputing with those variables is a good plan, as the MAR assumption is reasonable. But if you think the reason why age is missing is because of something not included in your data, then assuming MAR is not reasonable, and I would not impute under those circumstances.

> I know we are supposed to use multiple imputation if we can assume the missing values are missing at random. In my data, our two variables with missing values are missing because the subject refused to answer or because there were inconsistencies between weight and height (some BMI are missing) or because the subject did not know the answer. I should add that we only have 48 subjects with any missing data.

It would be great if you had an explanation for why people refused to answer items, but most of the time, we really don't. With 48 missing observations (out of many hundreds of subjects overall), the impact of imputation will likely be modest, and this can be checked by comparing results when you restrict to complete cases to results after imputation. But in general, I would be happy if you either excluded or imputed these subjects who chose not to give a response that could be used for Project 2. For subjects with "inconsistencies" this is indicative of some sort of data problem, perhaps a measurement error. In that setting, I'd be a little more circumspect, but again, make the case for what you feel is most appropriate in your setting and then do it is my advice for Project 2.

> Can you help me with (some particular situation) related to my project? (posted 2020-04-06)

Sure, but can we ask you to make it as easy as possible on us. What we want to be able to do is look at R output in addition to R code. We need to be able to recreate exactly (and I mean exactly) what you're looking at. With imputation involved, this becomes very challenging. What we want to see is what the implications of various decisions you have already made are, and what the implications would be of various suggestions for going forward in order to help you make sense of your data. 

1. The best solution is to settle on a version of your data set that you're happy with, then actively **save it as an Rds file within your R Markdown** so we know where in your file you created what you send to us, then send us the R Markdown, HTML result and R data set files, along with your questions. 
2. The second best solution is to send us the **raw `.csv` files** you are importing, using the names that are used in your R Markdown file to import them, along with your R Markdown and HTML files and questions.
3. If you cannot send us the raw data or the tidied data, helping you will be much more challenging, but we'd still like to try. At the least, we need an R Markdown and HTML file along with your questions.

> I'm having trouble getting the `cut` function to work properly in creating categories from a continuous variable. Any suggestions? (posted 2020-04-08)

My general approach to cutting variables by quartile is to use [the cut2 function from the Hmisc package](https://www.rdocumentation.org/packages/Hmisc/versions/4.4-0/topics/cut2) (which rms loads automatically) or to use the tidyverse's apporoach which is [cut_interval or cut_number or cut_width](https://ggplot2.tidyverse.org/reference/cut_interval.html) (all are part of ggplot2, I think) rather than [cut from the base R software](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cut). You might want to look at one of those options.

The most common thing I do when using any of these tools is to build a plot or table that shows me the old continuous data broken down by levels of the new categorical variable, to be sure I didn't introduce any missing values and that every subject falls into the category I intended them to fall into.

> How might I use a Poisson or other count outcome model if I have counts, but the minimum possible value is 1, instead of 0? (posted 2020-04-08)

Try a Poisson model on (Y - 1) rather than on your original response Y.

> Suppose I run my model with simple imputation and get result "A" and then run my model with multiple imputation and get result "NOT A". Which is the one I should report? (posted 2020-04-08)

This is a pretty clear indication that you need multiple imputation. I would report that as my final model. It's 100% reasonable to show this impact and then settle on the multiple imputation approach if you like.

> How should I explain my data cleaning and management work? (posted 2020-04-08)

Ideally, by explaining things (why you're doing them and what you're doing) in complete sentences before you show the code. And use subheadings, please. Bite the pieces off into small chunks and present the cleaning in multiple pieces as opposed to a wall of text.

> What's the most useful thing I can do to improve my project? (posted 2020-04-08)

Have someone else read it, looking for grammar and syntax issues, and for things that don't make sense. Ideally, you'd have cultivated friends in the class who can read your work. Happily, all of you have in the form of our TAs, but they're probably only available to read parts of your work - not the whole thing.

> I have a question about using the mice package to impute missing values. Specifically, how do we end up with a complete dataset? In the case of single imputation we can use: smart_16_imp1 <- mice::complete(smart_16_mice1) but in the case of multiple imputation, we end up with a pooled model of all 20 runs of our imputations. Is there a way to use this model to complete the data and fill in the missing values? If not, then what should the final analytic data set look like at the end of section 4? 

When using multiple imputation, you will thus create not one, but multiple data sets. Your final analytic data set that you create in Section 4 (and save as a tidy R data set) should be the data set including the missing values, after you've removed any cases that you will drop because of missing outcomes, but before you do any imputation, multiple or otherwise. That should also be what you display results for in Section 5. Your actual imputation work, then, should be confined to **Section 6** of the Project portfolio.

# Questions?

Questions about Project 2 should be directed to `431-help`.


